# DRL-ZeroDay-Detection

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)

Official implementation of **"Machine Learning-Based Zero-Day Attack Detection Using Deep Reinforcement Learning"** (Information Security Journal, 2024).

## ğŸ¯ Key Results

| Method | Accuracy | F1-Score | Zero-Day Detection | FP Rate |
|--------|----------|----------|-------------------|---------|
| **PPO (Ours)** | **91.7%** | **89.3%** | **83.4%** | 5.8% |
| DQN | 90.2% | 87.8% | 81.2% | 6.1% |
| A2C | 89.8% | 87.1% | 80.5% | 6.4% |
| XGBoost | 88.4% | 85.6% | 75.3% | 4.2% |
| Deep SVDD | 86.2% | 82.1% | 78.9% | 7.8% |

## ğŸš€ Quick Start

### Installation

```bash
git clone https://github.com/[username]/DRL-ZeroDay-Detection.git
cd DRL-ZeroDay-Detection
pip install -r requirements.txt
```

### Download Datasets

```bash
# See data/README_DATA.md for detailed instructions
python -m src.data_utils.preprocess_cicids2017
```

### Train PPO Model

```bash
# Using config file
python -m src.drl.train_drl --config configs/ppo_cicids2017.yaml

# Or with command line arguments
python -m src.drl.train_drl --model ppo --dataset cicids2017 --lambda_fn 10 --episodes 500
```

### Train Baselines

```bash
python -m src.baselines.train_baselines --dataset cicids2017
```

### Reproduce Paper Results

```bash
python -m experiments.reproduce_tables --all
```

## ğŸ“ Repository Structure

```
DRL-ZeroDay-Detection/
â”œâ”€â”€ configs/                    # Experiment configurations
â”‚   â”œâ”€â”€ ppo_cicids2017.yaml
â”‚   â”œâ”€â”€ dqn_cicids2017.yaml
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ README_DATA.md          # Dataset download instructions
â”‚   â”œâ”€â”€ raw/                    # Downloaded datasets
â”‚   â””â”€â”€ splits/                 # Preprocessed train/val/test splits
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ drl/                    # DRL implementations
â”‚   â”‚   â”œâ”€â”€ env_zero_day.py     # Gym environment
â”‚   â”‚   â”œâ”€â”€ dqn.py              # DQN agent
â”‚   â”‚   â”œâ”€â”€ ppo.py              # PPO agent
â”‚   â”‚   â”œâ”€â”€ a2c.py              # A2C agent
â”‚   â”‚   â””â”€â”€ train_drl.py        # Training script
â”‚   â”œâ”€â”€ baselines/              # Baseline methods
â”‚   â”‚   â””â”€â”€ train_baselines.py
â”‚   â”œâ”€â”€ data_utils/             # Preprocessing
â”‚   â”‚   â”œâ”€â”€ preprocess_cicids2017.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ evaluation/             # Metrics
â”‚       â””â”€â”€ metrics.py
â”œâ”€â”€ experiments/                # Reproduction scripts
â”‚   â””â”€â”€ reproduce_tables.py
â”œâ”€â”€ models/                     # Saved models
â”‚   â””â”€â”€ pretrained/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”¬ Method Overview

### Asymmetric Reward Function

Our key contribution is an asymmetric reward function that prioritizes attack detection:

```
R(s, a) = 
    +1   if correct classification
    -1   if false positive (normal â†’ attack)
    -Î»   if false negative (attack â†’ normal), Î»=10
```

The penalty ratio Î»=10 is justified by:
1. **Security criticality**: Missed attacks cost millions in breaches
2. **Class imbalance**: Compensates for attack rarity
3. **Exploration**: Encourages thorough classification of uncertain samples

### Attack-Family-Aware Splitting

To properly evaluate zero-day detection, we ensure test attacks are from *different families* than training:

| Dataset | Training Attacks | Test (Zero-Day) Attacks |
|---------|-----------------|------------------------|
| CICIDS2017 | DoS, DDoS, Port Scan, Brute Force | Web Attacks, Botnet, Infiltration |
| NSL-KDD | DoS, Probe | R2L, U2R |

## ğŸ“Š Datasets

| Dataset | Samples | Features | Source |
|---------|---------|----------|--------|
| NSL-KDD | 148,517 | 41 | [UNB](https://www.unb.ca/cic/datasets/nsl.html) |
| CICIDS2017 | 2,830,743 | 78 | [UNB](https://www.unb.ca/cic/datasets/ids-2017.html) |
| CIC-AndMal2017 | 10,854 | 80 | [UNB](https://www.unb.ca/cic/datasets/andmal2017.html) |
| Custom Zero-Day | 350,000 | 65 | This work (included) |

## âš¡ Computational Requirements

| Metric | Value |
|--------|-------|
| Training Time (PPO) | ~4.2 hours |
| Inference Latency | 0.21 ms/sample |
| Throughput | 4,762 samples/s (47K/s batched) |
| GPU Memory | 2.4 GB |
| Model Size | 18.7 MB |

**Hardware used**: NVIDIA RTX 3090, 64GB RAM, Intel i9-12900K

## ğŸ“– Citation

```bibtex
@article{yourname2024zerodaydrl,
  title={Machine Learning-Based Zero-Day Attack Detection Using Deep Reinforcement Learning},
  author={Your Name},
  journal={Information Security Journal},
  year={2024},
  doi={10.xxxx/xxxxx}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“¬ Contact

For questions or issues, please open an issue on GitHub or contact [your-email@example.com].
